{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecb65ad-760d-4859-8d44-0c778cb1f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in d:\\anaconda\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in d:\\anaconda\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8da22b-4e1a-40f6-9705-a96209a2a213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Log Likelihood: -801.98697050872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- SECTION 1: LOAD AND PREPARE DATA ---\n",
    "file_path = 'Survey_input.xlsx'\n",
    "\n",
    "# Load only the necessary sheets\n",
    "df_survey = pd.read_excel(file_path, sheet_name='Survey Results') # df = dataframe (Python's take on a table)\n",
    "df_design = pd.read_excel(file_path, sheet_name='Design matrix')\n",
    "\n",
    "# Clean Design Matrix\n",
    "# variable = pd.read_excel(file, sheet_name=string)\n",
    "df_design['Task'] = df_design['Task'].ffill() # when a group of rows are labelled together with one merged cell, this command copies the last read value to the next empty one \n",
    "df_design = df_design.dropna(subset=['Concept']).copy() # removes empty concept rows\n",
    "\n",
    "# --- SECTION 2: CALCULATE SUMMATIONS ---\n",
    "task_columns = [col for col in df_survey.columns if 'Task' in col] # counts no. of columns with task in it # [item for item in list if condition]\n",
    "choice_counts = {} #empty dictionary created which holds data holds data in pair sets (a \"key\" and a \"value\")\n",
    "\n",
    "# Tally up the survey choices\n",
    "for task_idx, col in enumerate(task_columns, start=1): # starts a loop that goes through each col,assigns a count (task_idx) starting at 1 # for counter, item in enumerate(list, start_number):\n",
    "    counts = df_survey[col].value_counts().to_dict()  # counts how many times a certain option was chosen and tallies it to a dictionary format # variable = dataframe[column].value_counts().to_dict()\n",
    "    for concept_choice, count in counts.items():\n",
    "        concept_key = 'None' if concept_choice == 4 else str(int(float(concept_choice))) # Handle 4 as 'None', others as integer strings\n",
    "        choice_counts[(task_idx, concept_key)] = count #saves finalcpunts to the master distionary, 'choice_counts'\n",
    "\n",
    "def clean_concept(x): #defines a custom reusable rule\n",
    "    if str(x).lower() == 'none' or pd.isna(x): # str() forces convertion to string, lower() converts to lower case; pd.insa(x) checks if the excel cell was empty\n",
    "        return 'None'\n",
    "    return str(int(float(x)))\n",
    "\n",
    "# Map the survey counts to the design matrix #!\n",
    "df_design['Summation'] = df_design.apply(\n",
    "    lambda row: choice_counts.get((int(float(row['Task'])), clean_concept(row['Concept'])), 0), axis=1\n",
    ")\n",
    "\n",
    "# --- SECTION 3: NULL MODEL CALCULATION ---\n",
    "# For a null model, all attribute part-worths (betas) are explicitly 0.\n",
    "# Therefore, the total utility (Total V) is exactly 0.0 for every option.\n",
    "df_design['Total V'] = 0.0\n",
    "\n",
    "# Calculate exponent, probabilities, and Log Likelihood\n",
    "df_design['exp(Vi)'] = np.exp(df_design['Total V']) # This equals 1.0 for all rows\n",
    "\n",
    "# P(i) calculations\n",
    "task_exp_sums = df_design.groupby('Task')['exp(Vi)'].transform('sum')\n",
    "df_design['P(i)'] = df_design['exp(Vi)'] / task_exp_sums\n",
    "\n",
    "# Log Likelihood components\n",
    "df_design['Log L components'] = df_design['Summation'] * np.log(df_design['P(i)'] + 1e-10)\n",
    "\n",
    "null_log_likelihood = df_design['Log L components'].sum()\n",
    "print(f\"Null Log Likelihood: {null_log_likelihood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9083dcf6-df39-4781-8040-eb488b23eff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
