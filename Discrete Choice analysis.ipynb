{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecb65ad-760d-4859-8d44-0c778cb1f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in d:\\anaconda\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in d:\\anaconda\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8da22b-4e1a-40f6-9705-a96209a2a213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Log Likelihood: -801.98697050872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- SECTION 1: LOAD AND PREPARE DATA ---\n",
    "file_path = 'Survey_input.xlsx'\n",
    "\n",
    "# Load only the necessary sheets\n",
    "df_survey = pd.read_excel(file_path, sheet_name='Survey Results') # df = dataframe (Python's take on a table)\n",
    "df_design = pd.read_excel(file_path, sheet_name='Design matrix')\n",
    "\n",
    "# Clean Design Matrix\n",
    "# variable = pd.read_excel(file, sheet_name=string)\n",
    "df_design['Task'] = df_design['Task'].ffill() # when a group of rows are labelled together with one merged cell, this command copies the last read value to the next empty one \n",
    "df_design = df_design.dropna(subset=['Concept']).copy() # removes empty concept rows\n",
    "\n",
    "# --- SECTION 2: CALCULATE SUMMATIONS ---\n",
    "task_columns = [col for col in df_survey.columns if 'Task' in col] # counts no. of columns with task in it # [item for item in list if condition]\n",
    "choice_counts = {} #empty dictionary created which holds data holds data in pair sets (a \"key\" and a \"value\")\n",
    "\n",
    "# Tally up the survey choices\n",
    "for task_idx, col in enumerate(task_columns, start=1): # starts a loop that goes through each col,assigns a count (task_idx) starting at 1 # for counter, item in enumerate(list, start_number):\n",
    "    counts = df_survey[col].value_counts().to_dict()  # counts how many times a certain option was chosen and tallies it to a dictionary format # variable = dataframe[column].value_counts().to_dict()\n",
    "    for concept_choice, count in counts.items():\n",
    "        concept_key = 'None' if concept_choice == 4 else str(int(float(concept_choice))) # Handle 4 as 'None', others as integer strings\n",
    "        choice_counts[(task_idx, concept_key)] = count #saves finalcpunts to the master distionary, 'choice_counts'\n",
    "\n",
    "def clean_concept(x): #defines a custom reusable rule\n",
    "    if str(x).lower() == 'none' or pd.isna(x): # str() forces convertion to string, lower() converts to lower case; pd.insa(x) checks if the excel cell was empty\n",
    "        return 'None'\n",
    "    return str(int(float(x)))\n",
    "\n",
    "# Map the survey counts to the design matrix #!\n",
    "df_design['Summation'] = df_design.apply(\n",
    "    lambda row: choice_counts.get((int(float(row['Task'])), clean_concept(row['Concept'])), 0), axis=1\n",
    ")\n",
    "\n",
    "# --- SECTION 3: NULL MODEL CALCULATION ---\n",
    "# For a null model, all attribute part-worths (betas) are explicitly 0.\n",
    "# Therefore, the total utility (Total V) is exactly 0.0 for every option.\n",
    "df_design['Total V'] = 0.0\n",
    "\n",
    "# Calculate exponent, probabilities, and Log Likelihood\n",
    "df_design['exp(Vi)'] = np.exp(df_design['Total V']) # This equals 1.0 for all rows\n",
    "\n",
    "# P(i) calculations\n",
    "task_exp_sums = df_design.groupby('Task')['exp(Vi)'].transform('sum')\n",
    "df_design['P(i)'] = df_design['exp(Vi)'] / task_exp_sums\n",
    "\n",
    "# Log Likelihood components\n",
    "df_design['Log L components'] = df_design['Summation'] * np.log(df_design['P(i)'] + 1e-10)\n",
    "\n",
    "null_log_likelihood = df_design['Log L components'].sum()\n",
    "print(f\"Null Log Likelihood: {null_log_likelihood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9083dcf6-df39-4781-8040-eb488b23eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |      100 |      1 |             - |             -\n",
      "     2 |      200 |      1 |  2.653899E+01 |         ideal\n",
      "     3 |      300 |      1 |  3.317038E+02 |         ideal\n",
      "     4 |      400 |      1 |  0.6418550115 |         ideal\n",
      "     5 |      500 |      1 |  4.468972E+01 |         ideal\n",
      "     6 |      600 |      1 |  2.551754E+01 |         ideal\n",
      "     7 |      700 |      1 |  2.285132E+01 |         ideal\n",
      "     8 |      800 |      1 |  2.125958E+01 |         ideal\n",
      "     9 |      900 |      1 |  0.000000E+00 |             f\n",
      "    10 |     1000 |      1 |  0.000000E+00 |             f\n",
      "    11 |     1100 |      1 |  1.7005822387 |         ideal\n",
      "    12 |     1200 |      1 |  0.6709351469 |         ideal\n",
      "    13 |     1300 |      1 |  1.8811075642 |         ideal\n",
      "    14 |     1400 |      1 |  0.1582087802 |         ideal\n",
      "    15 |     1500 |      1 |  0.000000E+00 |             f\n",
      "    16 |     1600 |      1 |  0.0624170225 |         ideal\n",
      "    17 |     1700 |      1 |  0.000000E+00 |             f\n",
      "    18 |     1800 |      1 |  0.1063247407 |         ideal\n",
      "    19 |     1900 |      1 |  0.000000E+00 |             f\n",
      "    20 |     2000 |      1 |  0.000000E+00 |             f\n",
      "    21 |     2100 |      1 |  0.0089482244 |         ideal\n",
      "    22 |     2200 |      1 |  0.0057378493 |         ideal\n",
      "    23 |     2300 |      1 |  0.000000E+00 |             f\n",
      "    24 |     2400 |      1 |  0.0068181088 |         ideal\n",
      "    25 |     2500 |      1 |  0.0195796311 |         ideal\n",
      "    26 |     2600 |      1 |  0.0086637960 |         ideal\n",
      "    27 |     2700 |      1 |  0.000000E+00 |             f\n",
      "    28 |     2800 |      1 |  0.000000E+00 |             f\n",
      "    29 |     2900 |      1 |  0.0045110949 |         ideal\n",
      "    30 |     3000 |      1 |  0.0212179230 |         ideal\n",
      "    31 |     3100 |      1 |  0.000000E+00 |             f\n",
      "    32 |     3200 |      1 |  0.000000E+00 |             f\n",
      "    33 |     3300 |      1 |  0.000000E+00 |             f\n",
      "    34 |     3400 |      1 |  0.000000E+00 |             f\n",
      "    35 |     3500 |      1 |  0.0034046016 |         ideal\n",
      "    36 |     3600 |      1 |  0.000000E+00 |             f\n",
      "    37 |     3700 |      1 |  0.000000E+00 |             f\n",
      "    38 |     3800 |      1 |  0.000000E+00 |             f\n",
      "    39 |     3900 |      1 |  0.0004408742 |             f\n",
      "    40 |     4000 |      1 |  0.0004408742 |             f\n",
      "    41 |     4100 |      1 |  0.0004408742 |             f\n",
      "    42 |     4200 |      1 |  0.0008344255 |             f\n",
      "    43 |     4300 |      1 |  0.0016199749 |             f\n",
      "    44 |     4400 |      1 |  0.0016199749 |             f\n",
      "    45 |     4500 |      1 |  0.0016199749 |             f\n",
      "    46 |     4600 |      1 |  0.0016225357 |             f\n",
      "    47 |     4700 |      1 |  0.0019265581 |             f\n",
      "    48 |     4800 |      1 |  0.0019382712 |             f\n",
      "    49 |     4900 |      1 |  0.0020277523 |             f\n",
      "    50 |     5000 |      1 |  0.0025806061 |         ideal\n",
      "\n",
      "--- OPTIMIZATION COMPLETE ---\n",
      "Maximum Log Likelihood: -438.34692553403835\n",
      "Beta for Cut width: 0.9657\n",
      "Beta for Engine disp: 0.8910\n",
      "Beta for Price: -1.5070\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "# --- SECTION 1: DEFINE YOUR ATTRIBUTES ---\n",
    "# These exactly match the headers in your 'Design matrix'\n",
    "attribute_columns = ['Cut width', 'Engine disp', 'Price'] \n",
    "\n",
    "# Fill blank cells in the 'None' option rows with 0.\n",
    "# This prevents math errors and anchors the baseline utility.\n",
    "df_design[attribute_columns] = df_design[attribute_columns].fillna(0)\n",
    "\n",
    "# --- SECTION 2: BUILD THE PROBLEM ENVIRONMENT ---\n",
    "class MNL_Optimization(ElementwiseProblem):\n",
    "    def __init__(self, df, attr_cols):\n",
    "        # Extract the necessary data as arrays for faster calculation\n",
    "        self.X_matrix = df[attr_cols].values\n",
    "        self.tasks = df['Task'].values\n",
    "        self.summations = df['Summation'].values\n",
    "        \n",
    "        # Define the number of betas to find (n_var) and objectives (n_obj)\n",
    "        n_variables = len(attr_cols)\n",
    "        \n",
    "        # Set boundaries for the beta values (xl = lower limit, xu = upper limit)\n",
    "        super().__init__(n_var=n_variables, n_obj=1, xl=-10, xu=10)\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        # x represents a temporary 'guess' for the beta values\n",
    "        \n",
    "        # 1. Calculate Utilities: V = X * Betas\n",
    "        V = np.dot(self.X_matrix, x)\n",
    "        exp_V = np.exp(V)\n",
    "\n",
    "        # 2. Calculate Probabilities using a temporary table\n",
    "        temp_df = pd.DataFrame({\n",
    "            'Task': self.tasks, \n",
    "            'exp_V': exp_V, \n",
    "            'Summation': self.summations\n",
    "        })\n",
    "        task_sums = temp_df.groupby('Task')['exp_V'].transform('sum')\n",
    "        P_i = temp_df['exp_V'] / task_sums\n",
    "\n",
    "        # 3. Calculate Log-Likelihood\n",
    "        LL_components = temp_df['Summation'] * np.log(P_i + 1e-10)\n",
    "        log_likelihood = LL_components.sum()\n",
    "\n",
    "        # 4. Pymoo always MINIMIZES. To maximize LL, we minimize negative LL.\n",
    "        out[\"F\"] = -log_likelihood\n",
    "\n",
    "# --- SECTION 3: RUN THE NSGA-II SOLVER ---\n",
    "# Initialize the custom problem\n",
    "problem = MNL_Optimization(df_design, attribute_columns)\n",
    "\n",
    "# Configure the algorithm settings\n",
    "algorithm = NSGA2(pop_size=100)\n",
    "\n",
    "# Execute the search\n",
    "results = minimize(\n",
    "    problem,\n",
    "    algorithm,\n",
    "    ('n_gen', 50), # Number of generations to evolve\n",
    "    seed=1,\n",
    "    verbose=True   # Prints progress as it runs\n",
    ")\n",
    "\n",
    "# --- SECTION 4: DISPLAY RESULTS ---\n",
    "print(\"\\n--- OPTIMIZATION COMPLETE ---\")\n",
    "print(f\"Maximum Log Likelihood: {-results.F[0]}\")\n",
    "\n",
    "# Pair the final beta values with their column names\n",
    "for attr, beta in zip(attribute_columns, results.X):\n",
    "    print(f\"Beta for {attr}: {beta:.4f}\")\n",
    "\n",
    "# --- SECTION 5: UPDATE MAIN DATAFRAME ---\n",
    "# Calculate the final optimized utilities and add them back to the design matrix\n",
    "df_design['Final V'] = np.dot(df_design[attribute_columns].values, results.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a667f3-e0f7-497d-85c0-bd1e302cf6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
